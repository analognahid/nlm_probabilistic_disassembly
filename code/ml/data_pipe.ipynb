{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d3e234-741d-493b-89f7-f00b39b6ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "import torch\n",
    "\n",
    "accelerator = Accelerator()\n",
    "accelerator.state.num_processes = 3  # For 3 GPUs\n",
    "device = accelerator.device\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a994e3c-4bb4-4196-840d-3c78c182596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys, json,re, pickle\n",
    "import magic, hashlib,  traceback ,ntpath, collections ,lief\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "import torch.nn as nn\n",
    "import lief\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from transformers import AdamW,AutoTokenizer\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score,f1_score, confusion_matrix,mean_squared_error, mean_absolute_error, r2_score\n",
    "from numpy import *\n",
    "from num2words import num2words\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f654b05f-145b-405f-b917-6bd69545e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_FILE_TYPE = 'PE' #or ELF\n",
    "bin_path = '/home/raisul/DATA/temp/x86_pe_msvc_O2_static/'\n",
    "bin_files = [os.path.join(bin_path, f) for f in os.listdir(bin_path) if f.endswith(\".exe\")]\n",
    "ground_truth_path ='/home/raisul/DATA/temp/ghidra_x86_pe_msvc_O2_debug/'  \n",
    "MODEL_SAVE_PATH= '/home/raisul/probabilistic_disassembly/models/'\n",
    "EXPERIMENT_NAME = 'prototype_pe_small'\n",
    "MAX_TOKEN_SIZE = 120\n",
    "MAX_SEQUENCE_LENGTH = 10\n",
    "VOCAB_SIZE = 500\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af8e984-c7ac-4ce3-9978-2f8128e992ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_num_with_word(input_string , replace_dict):\n",
    "    def num_to_word(match):\n",
    "        number = int( match.group(0))\n",
    "        return num2words(replace_dict[number]).replace(' ','').replace('-',\"\")\n",
    "    result_string = re.sub(r'\\b\\d+\\b', num_to_word, input_string)\n",
    "    return result_string\n",
    "\n",
    "\n",
    "\n",
    "def replace_hex_with_decimal(input_string):\n",
    "    # Regular expression to find hexadecimal numbers prefixed with \"0x\" or \"0X\"\n",
    "    hex_pattern = r'0[xX][0-9a-fA-F]+'\n",
    "    \n",
    "    # Function to convert each found hex number to decimal\n",
    "    def hex_to_decimal(match):\n",
    "        hex_value = match.group(0)  # Extract the matched hex number\n",
    "        decimal_value = str(int(hex_value, 16))  # Convert hex to decimal\n",
    "        return decimal_value\n",
    "    # Substitute all hex numbers in the string with their decimal equivalents\n",
    "    result_string = re.sub(hex_pattern, hex_to_decimal, input_string)\n",
    "    return result_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d01dfce-edb1-4a0a-a0a8-fbaf3fac12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ground_truth_ghidra(exe_path, text_section_offset , text_section_len):\n",
    "\n",
    "    text_sextion_end = text_section_offset + text_section_len\n",
    "    \n",
    "    elf_file_name = os.path.basename(exe_path)\n",
    "    ghidra_file_path = os.path.join(ground_truth_path, elf_file_name.split('.')[0]) + '.json'\n",
    "    \n",
    "    with open(ghidra_file_path, \"r\") as file:\n",
    "        ghidra_data = json.load(file)\n",
    "\n",
    "    ground_truth_offsets = list(ghidra_data.keys())\n",
    "\n",
    "    ground_truth_offsets = [int(i) for i in ground_truth_offsets]\n",
    "    ground_truth_offsets = [x for x in ground_truth_offsets if text_section_offset <= x <= text_sextion_end]\n",
    "    ground_truth_offsets.sort()\n",
    "    return ground_truth_offsets\n",
    "\n",
    "\n",
    "\n",
    "def find_data_in_textsection(ground_truth_offsets , text_section_offset , text_section_len, offset_inst_dict):\n",
    "    data_offsets = []\n",
    "    for i in range(1, len(ground_truth_offsets)-1):\n",
    "        distance = ground_truth_offsets[i+1] - ground_truth_offsets[i]\n",
    "\n",
    "        inst_len = offset_inst_dict[ground_truth_offsets[i]].size \n",
    "        \n",
    "        if distance!=inst_len:\n",
    "            # print('offset_ranges[i]: ',ground_truth_offsets[i] , 'offset_ranges[i-1]: ',ground_truth_offsets[i-1], ' inst_len: ',inst_len  )\n",
    "            # print(ground_truth_offsets[i],' ' ,hex(ground_truth_offsets[i]) , offset_inst_dict[ground_truth_offsets[i]], ' len',offset_inst_dict[ground_truth_offsets[i]].size )\n",
    "            # print(\"\\nByte GAP ###### \",distance ,' Missing bytes: ', distance - inst_len)\n",
    "            \n",
    "            for j in range( ground_truth_offsets[i] +inst_len , ground_truth_offsets[i+1]  ):\n",
    "                data_offsets.append(j)\n",
    "                # if offset_inst_dict[j]:\n",
    "                #     print(\"# \",j, offset_inst_dict[j].mnemonic, offset_inst_dict[j].op_str , 'inst len:',offset_inst_dict[j].size )\n",
    "                # else:\n",
    "                #     print(\"# \",j, \" invalid \")\n",
    "            # print('\\n')\n",
    "        else:\n",
    "            # print(ground_truth_offsets[i],' ', hex(ground_truth_offsets[i]) , offset_inst_dict[ground_truth_offsets[i]].mnemonic,offset_inst_dict[ground_truth_offsets[i]].op_str ,' len',offset_inst_dict[ground_truth_offsets[i]].size)\n",
    "            pass\n",
    "    return data_offsets\n",
    "    \n",
    "\n",
    "def linear_sweep(offset_inst , target_offset):\n",
    "    inst_sequence = ''\n",
    "    address_list = []\n",
    "    \n",
    "    current_offset = target_offset\n",
    "    for q in range(MAX_SEQUENCE_LENGTH):\n",
    "\n",
    "        if current_offset in offset_inst: #if end of text section\n",
    "            current_instruction = offset_inst[current_offset]\n",
    "            if current_instruction is None:\n",
    "                return  None\n",
    "                \n",
    "            current_offset = current_offset + current_instruction.size\n",
    "            inst_sequence+= str( hex(current_instruction.address)) +\" \"+ current_instruction.mnemonic +' '+ current_instruction.op_str+ ' ; ' \n",
    "            address_list.append(current_instruction.address)\n",
    "            \n",
    "            if current_instruction.mnemonic in [\"ret\", \"jmp\"]: #break linear sweep\n",
    "                break\n",
    "                \n",
    "\n",
    "    return inst_sequence, address_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2f8ec7-72bd-4fd8-aef3-90ef4e0fcaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# SEQUENCES = []\n",
    "# LABELS     = []\n",
    "\n",
    "# for bin_file_path in bin_files:\n",
    "\n",
    "    \n",
    "#     md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "#     md.detail = True\n",
    "#     offset_inst = {}\n",
    "\n",
    "    \n",
    "#     with open(bin_file_path, 'rb') as f:\n",
    "\n",
    "#         try:\n",
    "#             if BIN_FILE_TYPE == \"ELF\":\n",
    "#                 elffile = ELFFile(f)\n",
    "#                 textSection = elffile.get_section_by_name('.text').data()\n",
    "#                 text_section_offset = elffile.get_section_by_name('.text')['sh_offset']\n",
    "              \n",
    "#             elif BIN_FILE_TYPE == \"PE\":\n",
    "\n",
    "                        \n",
    "#                 pe_file = lief.parse(bin_file_path)\n",
    "#                 text_section = pe_file.get_section(\".text\")\n",
    "#                 text_section_offset = text_section.pointerto_raw_data\n",
    "#                 textSection = bytes(text_section.content)\n",
    "                \n",
    "#             ground_truth_offsets = get_ground_truth_ghidra(bin_file_path, text_section_offset , len(textSection))\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(\"An error occurred:\", e ,bin_file_path)\n",
    "#             continue\n",
    "\n",
    "#     for byte_index in range(len(textSection)):\n",
    "#         try:    \n",
    "\n",
    "#             instruction = next(md.disasm(textSection[byte_index: byte_index+15 ], text_section_offset + byte_index ), None)\n",
    "#             offset_inst[text_section_offset+byte_index] = instruction\n",
    "            \n",
    "#             # if instruction:\n",
    "#             #     print(\"%d:\\t%s\\t%s _\\t%x\" %(int(instruction.address), instruction.mnemonic, instruction.op_str, instruction.size))\n",
    "#             # else:\n",
    "#             #     print(\"%d:\\t%s \" % (text_section_offset + byte_index  , 'invalid instruction') )\n",
    "                \n",
    "            \n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(traceback.print_exc() )\n",
    "#             print(e)\n",
    "\n",
    "    \n",
    "    \n",
    "#     offset_inst_dict = collections.OrderedDict(sorted(offset_inst.items()))\n",
    "\n",
    "#     DATA_OFFSETS = find_data_in_textsection(ground_truth_offsets , text_section_offset , len(textSection) , offset_inst)\n",
    "\n",
    "\n",
    "    \n",
    "#     for byte_offset in range(text_section_offset, text_section_offset+len(textSection)):\n",
    "#         return_value = linear_sweep(offset_inst_dict ,  byte_offset )\n",
    "#         if return_value== None:\n",
    "#             continue\n",
    "#         inst_seq, inst_addresses = return_value \n",
    "#         ###################################################################\n",
    "#         ## number to words\n",
    "#         disassembly_decimal = replace_hex_with_decimal(inst_seq)\n",
    "\n",
    "#         #num to words all\n",
    "#         numbers = [int(s) for s in re.findall(r'\\b\\d+\\b', disassembly_decimal)]\n",
    "#         numbers = sorted(set(numbers) , reverse=True)\n",
    "#         number_word_dict = {}\n",
    "        \n",
    "#         for ix,n in enumerate(numbers):\n",
    "#             number_word_dict[n] = len(numbers)-1 -ix\n",
    "\n",
    "#         disassembly_num_to_words = replace_num_with_word(disassembly_decimal , number_word_dict)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "#         ###########################################################################\n",
    "        \n",
    "        \n",
    "#         SEQUENCES.append(disassembly_num_to_words ) #os.path.basename(bin_file_path)+\"_\"+str(byte_offset)+\"_\"+\n",
    "#         if byte_offset in ground_truth_offsets:\n",
    "#             LABELS.append(float(1))\n",
    "#         else:\n",
    "#             LABELS.append(float(0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Downsample \n",
    "# data = pd.DataFrame({\"text\": SEQUENCES, \"label\": LABELS})\n",
    "\n",
    "# # Split by label\n",
    "# zeros = data[data[\"label\"] == 0]\n",
    "# ones = data[data[\"label\"] == 1]\n",
    "\n",
    "# # Downsample zeros to 10%\n",
    "# zeros_downsampled = zeros.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# # Combine and shuffle\n",
    "# balanced_data = pd.concat([zeros_downsampled, ones]).sample(frac=1, random_state=42)\n",
    "\n",
    "# # Extract final lists\n",
    "# SEQUENCES = balanced_data[\"text\"].tolist()\n",
    "# LABELS = balanced_data[\"label\"].tolist()\n",
    "\n",
    "# print(len(SEQUENCES) , len(LABELS))\n",
    "# print(LABELS.count(0), LABELS.count(1))\n",
    "\n",
    "# with open(MODEL_SAVE_PATH+'training_data.ignore.pkl', 'wb') as f:\n",
    "#     pickle.dump([SEQUENCES,LABELS], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e0da24-481e-423d-aa66-07465ec4fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load from file\n",
    "with open(MODEL_SAVE_PATH+'training_data.ignore.pkl', 'rb') as f:\n",
    "    SEQUENCES,LABELS = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28176656-c7b2-4fad-a962-0f2b8963c5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  >  two call zero ; three jmp one ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two call one ; three add rsp, zero ; four jmp five ;  \n",
      "\n",
      "1.0  >  two test sil, sil ; three jne five ; four call eleven ; five xor edx, edx ; six mov cl, zero ; seven call one ; eight mov eax, ebx ; nine jmp ten ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  four mov dword ptr [rbp - three], eax ; five xor r9d, seventeen ; six mov dword ptr [rbp - two], ebx ; seven or r10d, r9d ; eight mov dword ptr [rbp - one], ecx ; nine mov edi, ecx ; ten mov dword ptr [rbp - zero], edx ; eleven jne fourteen ; twelve or qword ptr [rip + fifteen], eighteen ; thirteen and eax, sixteen ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  six mov r9d, ebx ; seven mov dword ptr [rbp - four], ecx ; eight mov dword ptr [rbp - two], edx ; nine bt ebx, five ; ten jae thirteen ; eleven or r8d, one ; twelve mov dword ptr [rip + seventeen], r8d ; thirteen cmp eax, zero ; fourteen jl sixteen ; fifteen mov eax, three ;  \n",
      "\n",
      "1.0  >  five call qword ptr [rip + eleven] ; six test byte ptr [rsp + two], zero ; seven mov eax, one ; eight cmovne ax, word ptr [rsp + three] ; nine add rsp, four ; ten ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero ret  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  two mov edx, ecx ; three mov ecx, dword ptr [rax] ; four call one ; five nop  ; six add rsp, zero ; seven pop rbp ; eight ret  ;  \n",
      "\n",
      "1.0  >  three mov byte ptr [rip + twelve], zero ; four call two ; five call one ; six test al, al ; seven jne ten ; eight xor al, al ; nine jmp eleven ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two add eax, sixteen ; three cmp eax, one ; four ja twelve ; five movabs rcx, seventeen ; six bt rcx, rax ; seven jae twelve ; eight mov r8d, dword ptr [rip + fifteen] ; nine or r8d, zero ; ten mov dword ptr [rip + fourteen], r8d ; eleven jmp thirteen ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one sub rsp, zero ; two mov r8, rcx ; three mov eax, sixteen ; four cmp word ptr [rip - thirteen], ax ; five jne eleven ; six movsxd rcx, dword ptr [rip - twelve] ; seven lea rdx, [rip - fourteen] ; eight add rcx, rdx ; nine cmp dword ptr [rcx], fifteen ; ten jne eleven ;  \n",
      "\n",
      "1.0  >  three mov ecx, dword ptr [r9 + one] ; four cmp rdx, rcx ; five jb ten ; six mov eax, dword ptr [r9 + zero] ; seven add eax, ecx ; eight cmp rdx, rax ; nine jb thirteen ; ten add r9, two ; eleven cmp r9, r8 ; twelve jne three ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two cmp word ptr [rip - fourteen], ax ; three jne twelve ; four movsxd rcx, dword ptr [rip - thirteen] ; five lea rdx, [rip - fifteen] ; six add rcx, rdx ; seven cmp dword ptr [rcx], sixteen ; eight jne twelve ; nine mov eax, one ; ten cmp word ptr [rcx + zero], ax ; eleven jne twelve ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  five and al, three ; six add byte ptr [rsi + two], dh ; seven cmp qword ptr [rsp + four], zero ; eight jne ten ; nine mov dword ptr [rsp + three], zero ; ten cmp dword ptr [rsp + three], one ; eleven jbe fifteen ; twelve mov eax, dword ptr [rsp + three] ; thirteen dec eax ; fourteen mov dword ptr [rsp + three], eax ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven lea rdx, [rip + ten] ; eight lea rax, [rip + eleven] ; nine sub rcx, rdx ;  \n",
      "\n",
      "1.0  >  four cmp ebp, dword ptr [rsp + one] ; five jl three ; six mov rcx, r13 ; seven call qword ptr [rip + seventeen] ; eight mov rcx, qword ptr [rsp + zero] ; nine call qword ptr [rip + sixteen] ; ten mov rcx, qword ptr [rsp + two] ; eleven call qword ptr [rip + fifteen] ; twelve mov rcx, r12 ; thirteen call qword ptr [rip + fourteen] ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two mov dword ptr [rip + sixteen], eax ; three test r9b, one ; four je twelve ; five or eax, one ; six mov dword ptr [rip + fifteen], zero ; seven mov dword ptr [rip + fourteen], eax ; eight mov ecx, seventeen ; nine mov rax, qword ptr [rip + thirteen] ; ten and r9d, ecx ; eleven and rax, eighteen ;  \n",
      "\n",
      "1.0  >  six mov qword ptr [rsp + one], rbx ; seven mov qword ptr [rsp + two], rsi ; eight push rdi ; nine sub rsp, four ; ten mov ecx, zero ; eleven call five ; twelve test al, al ; thirteen je sixteen ; fourteen xor sil, sil ; fifteen mov byte ptr [rsp + three], sil ;  \n",
      "\n",
      "1.0  >  three push rdi ; four sub rsp, two ; five mov rbx, qword ptr [rcx] ; six mov rdi, rcx ; seven cmp dword ptr [rbx], fifteen ; eight jne thirteen ; nine cmp dword ptr [rbx + one], zero ; ten jne thirteen ; eleven mov edx, dword ptr [rbx + two] ; twelve lea eax, [rdx - fourteen] ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one mov rax, qword ptr [rip + ten] ; two or dword ptr [rip + eleven], zero ; three and rax, twelve ; four mov dword ptr [rip + nine], ebx ; five mov qword ptr [rip + eight], rax ; six jmp seven ;  \n",
      "\n",
      "1.0  >  zero ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two jbe ten ; three cmp edx, eleven ; four je ten ; five mov rbx, qword ptr [rsp + one] ; six xor eax, eax ; seven add rsp, zero ; eight pop rdi ; nine ret  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "1.0  >  four lea ecx, [rax + zero] ; five call one ; six mov rbx, qword ptr [rsp + three] ; seven add rsp, two ; eight pop rbp ; nine ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one add rsp, zero ; two ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero add byte ptr [rax], al ; one jmp two ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  four push rbx ; five sub rsp, one ; six cmp byte ptr [rip + fifteen], zero ; seven mov bl, cl ; eight je eleven ; nine test dl, dl ; ten jne fourteen ; eleven call three ; twelve mov cl, bl ; thirteen call two ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  five loopne four ; six insb byte ptr [rdi], dx ; seven out three, al ; eight clc  ; nine add dh, byte ptr [rsi + zero] ; ten cmp edx, sixteen ; eleven je fifteen ; twelve mov rbx, qword ptr [rsp + two] ; thirteen xor eax, eax ; fourteen add rsp, one ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero add byte ptr fs:[rax], al ; one add eax, fourteen ; two add eax, thirteen ; three mov ecx, fifteen ; four mov rax, qword ptr [rip + twelve] ; five and r9d, ecx ; six and rax, sixteen ; seven mov qword ptr [rip + eleven], rax ; eight cmp r9d, ecx ; nine jne ten ;  \n",
      "\n",
      "1.0  >  one je three ; two call rax ; three add rsp, zero ; four ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  four pop rsp ; five and al, zero ; six mov qword ptr [rsp + one], rbp ; seven mov qword ptr [rsp + two], rsi ; eight push rdi ; nine sub rsp, three ; ten mov rbx, r9 ; eleven mov rdi, r8 ; twelve mov rsi, rdx ; thirteen mov rbp, rcx ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  one loopne zero ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ; ten int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  three mov r9d, ebx ; four mov r14d, eax ; five xor ecx, ecx ; six mov eax, zero ; seven cpuid  ; eight or r10d, r8d ; nine mov dword ptr [rbp - two], eax ; ten xor r9d, thirteen ; eleven mov dword ptr [rbp - one], ebx ; twelve or r10d, r9d ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one lea rdx, [rip + nine] ; two lea rcx, [rip + eight] ; three call seven ; four mov dword ptr [rip + ten], zero ; five jmp six ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two mov rbx, rax ; three cmp qword ptr [rax], zero ; four je eleven ; five mov rcx, rax ; six call one ; seven test al, al ; eight je eleven ; nine mov rcx, qword ptr [rbx] ; ten call thirteen ; eleven call twelve ;  \n",
      "\n",
      "1.0  >  three mov ecx, dword ptr [rax + one] ; four mov rax, qword ptr [rbx + one] ; five test byte ptr [rcx + rax + zero], two ; six je ten ; seven movzx eax, byte ptr [rcx + rax + zero] ; eight and eax, thirteen ; nine add r9, rax ; ten xor r9, rdx ; eleven mov rcx, r9 ; twelve pop rbx ;  \n",
      "\n",
      "1.0  >  three call two ; four movsxd rcx, dword ptr [rsi] ; five mov r8, r15 ; six test rcx, rcx ; seven js thirteen ; eight mov eax, dword ptr [rsp + one] ; nine cmp dword ptr [rbx + r8*zero], eax ; ten je fourteen ; eleven inc r8 ; twelve cmp r8, rcx ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one ret zero ;  \n",
      "\n",
      "1.0  >  zero lea rax, [rip + seven] ; one sub rcx, rdx ; two sub rax, rdx ; three cmp rcx, rax ; four ja six ; five int3  ; six ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  seven mov r8, rbx ; eight lea rcx, [rbp + six] ; nine mov qword ptr [rsp + two], rcx ; ten lea rcx, [rbp - zero] ; eleven mov qword ptr [rsp + one], rcx ; twelve xor ecx, ecx ; thirteen call qword ptr [rip + seventeen] ; fourteen mov rax, qword ptr [rbp + five] ; fifteen lea rcx, [rsp + three] ; sixteen mov qword ptr [rbp + four], rax ;  \n",
      "\n",
      "1.0  >  six call three ; seven lea rcx, [rip - five] ; eight call one ; nine call two ; ten mov ecx, eax ; eleven call seventeen ; twelve test eax, eax ; thirteen jne sixteen ; fourteen call zero ; fifteen call four ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one test rax, rax ; two je four ; three call qword ptr [rip + six] ; four add rsp, zero ; five ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  four call three ; five mov rbx, rax ; six cmp qword ptr [rax], zero ; seven je fourteen ; eight mov rcx, rax ; nine call two ; ten test al, al ; eleven je fourteen ; twelve xor r8d, r8d ; thirteen lea edx, [r8 + one] ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  three test ecx, ecx ; four jne six ; five mov byte ptr [rip + fourteen], zero ; six call two ; seven call one ; eight test al, al ; nine jne twelve ; ten xor al, al ; eleven jmp thirteen ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two mov qword ptr [rsp], rdx ; three cmp rdx, r9 ; four je thirteen ; five mov ecx, dword ptr [rdx + one] ; six cmp r8, rcx ; seven jb twelve ; eight mov eax, dword ptr [rdx + zero] ; nine add eax, ecx ; ten cmp r8, rax ; eleven jb fourteen ;  \n",
      "\n",
      "1.0  >  one cmp eax, thirteen ; two je eleven ; three cmp eax, fourteen ; four je eleven ; five add eax, fifteen ; six cmp eax, zero ; seven ja twelve ; eight movabs rcx, sixteen ; nine bt rcx, rax ; ten jae twelve ;  \n",
      "\n",
      "1.0  >  five sub r8, rdx ; six movzx edx, word ptr [rcx + three] ; seven add rdx, four ; eight add rdx, rcx ; nine movzx eax, word ptr [rcx + one] ; ten lea rcx, [rax + rax*zero] ; eleven lea r9, [rdx + rcx*two] ; twelve mov qword ptr [rsp], rdx ; thirteen cmp rdx, r9 ; fourteen je fifteen ;  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for j in range(100):\n",
    "    if True:#'int3' in SEQUENCES[j]: #LABELS[j] :\n",
    "        print(LABELS[j] , ' > ' , SEQUENCES[j] ,'\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085fe09-aecf-49e1-b145-acea85d14365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0307133-f04b-43dc-b48f-1a71d755ce83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "from transformers import BertTokenizer,BertForSequenceClassification\n",
    "\n",
    "# If using a character-level tokenizer for sequences like DNA/Protein:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")#BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer.train_new_from_iterator(SEQUENCES, VOCAB_SIZE)\n",
    "\n",
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     'bert-base-uncased',\n",
    "#     num_labels=1  \n",
    "# )\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_SAVE_PATH +EXPERIMENT_NAME,\n",
    "    num_labels=1  \n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(VOCAB_SIZE)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optim = AdamW( model.parameters() , lr=1e-5, eps = 1e-6, betas=(0.9,0.98), weight_decay=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2517e6b5-4b9b-4678-b78d-1243f0fc471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two call zero ; three jmp one ; '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCES[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4129cd-e356-4327-9e23-72beed13b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        # Tokenize the \n",
    "        tokenized_text = (self.tokenizer(text , max_length= MAX_TOKEN_SIZE,padding='max_length', truncation=True , return_tensors='pt')).to(device)\n",
    "        \n",
    "        return tokenized_text, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa283cd-ae7b-4b14-aef8-d197ca0ad338",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BinaryDataset(SEQUENCES, LABELS,tokenizer)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "validation_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset  = torch.utils.data.Subset(dataset, range(train_size))\n",
    "validation_dataset = torch.utils.data.Subset(dataset, range(train_size , len(dataset)))\n",
    "\n",
    "# train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size] , generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f4ecfe2-f33d-42e8-aba0-f9e506fd401c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2022207, 505552)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(train_dataset) , len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62c119b9-3fb7-4264-be17-e50d77f81283",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE ,shuffle=False) \n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f3296ff-458f-48d5-be35-85e6dcd7a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optim, train_loader,validation_loader = accelerator.prepare(model, optim, train_loader,validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fff2a619-6a06-4774-8ec7-bad9a55e8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model ,data_loop, is_training = False):\n",
    "    \n",
    "    prediction_s, ground_truth_s = [], []\n",
    "    losses = []\n",
    "\n",
    "    for N,batch in enumerate(data_loop):\n",
    "        # Forward pass\n",
    "        if is_training == True:\n",
    "            optim.zero_grad()\n",
    "        \n",
    "        batch_input, batch_labels = batch\n",
    "        if len(batch_labels)<BATCH_SIZE:\n",
    "            continue\n",
    "            \n",
    "        batch_input_ids= batch_input['input_ids']\n",
    "        batch_attention_mask=batch_input['attention_mask']\n",
    "        batch_token_type_ids =batch_input['token_type_ids']\n",
    "        \n",
    "        outputs = model(input_ids=batch_input_ids.squeeze(),\n",
    "                        attention_mask=batch_attention_mask.squeeze(),\n",
    "                        token_type_ids=batch_token_type_ids.squeeze(),\n",
    "                        labels=batch_labels.float() )\n",
    "        \n",
    "#\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        predictions = logits.squeeze()\n",
    "        # print(logits ,predictions )\n",
    "\n",
    "        prediction_s.extend(predictions.detach().cpu().numpy().flatten())\n",
    "        ground_truth_s.extend(batch_labels.detach().cpu().numpy().flatten())\n",
    "\n",
    "\n",
    "        if is_training == True:\n",
    "            # loss.backward()\n",
    "            accelerator.backward(loss)\n",
    "            optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        data_loop.set_description(f'Epoch {ecpoch}')\n",
    "        data_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Evaluation Metrics\n",
    "    mse = mean_squared_error(ground_truth_s, prediction_s)\n",
    "    rmse = sqrt(mse)\n",
    "    mae = mean_absolute_error(ground_truth_s, prediction_s)\n",
    "    r2 = r2_score(ground_truth_s, prediction_s)\n",
    "    \n",
    "\n",
    "    metrices = {'MSE':mse ,\n",
    "                      'RMSE':rmse, \n",
    "                      'MAE':mae, \n",
    "                      'R²':r2,\n",
    "                      'loss': (sum(losses) / len(losses))}\n",
    "    return metrices , prediction_s, ground_truth_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fd188e0-a6f3-4f5f-b9a6-5a9040dd42e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                | 8/4045 [00:11<1:36:08,  1.43s/it, loss=0.000209]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m train_loop \u001b[38;5;241m=\u001b[39m tqdm(train_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 12\u001b[0m metrices,prediction_s, ground_truth_s  \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m global_metrices\u001b[38;5;241m.\u001b[39mappend(metrices)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining metrices \u001b[39m\u001b[38;5;124m\"\u001b[39m,metrices)\n",
      "Cell \u001b[0;32mIn[16], line 40\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, data_loop, is_training)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_training \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     accelerator\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m---> 40\u001b[0m     \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# print relevant info to progress bar\u001b[39;00m\n\u001b[1;32m     42\u001b[0m data_loop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mecpoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/accelerate/optimizer.py:171\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/transformers/optimization.py:656\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    653\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    654\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m step_size \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2) \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[0;32m--> 656\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# Just adding the square of the weights to the loss function is *not*\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# the correct way of using L2 regularization/weight decay with Adam,\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# since that will interact with the m and v parameters in strange ways.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# of the weights to the loss with plain (non-momentum) SGD.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;66;03m# Add weight decay at the end (fixed version)\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "global_metrices = []\n",
    "v_global_metrices = []\n",
    "\n",
    "\n",
    "for ecpoch in range(EPOCHS):\n",
    "    \n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    model.train()\n",
    "    metrices,prediction_s, ground_truth_s  = training_loop(model ,train_loop, is_training = True)\n",
    "    global_metrices.append(metrices)\n",
    "    print(\"Training metrices \",metrices)\n",
    "     \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        validation_loop = tqdm(validation_loader, leave=True)\n",
    "        v_metrices, v_prediction_s, v_ground_truth_s  = training_loop(model ,validation_loop, is_training = False)\n",
    "\n",
    "\n",
    "        demo_len =100000\n",
    "        for i in range(int(minimum(demo_len , len(v_prediction_s) ))):\n",
    "\n",
    "            print('\\n')\n",
    "            generated_text = tokenizer.decode(validation_dataset[i][0].input_ids[0],skip_special_tokens=True).split('[SEP]')[0]\n",
    "            print( v_prediction_s[i], v_ground_truth_s[i] , '\\n' , generated_text)\n",
    "\n",
    "\n",
    "           \n",
    "        print( 'v_metrices: ',v_metrices )\n",
    "        v_global_metrices.append(v_metrices)\n",
    "        \n",
    "    if accelerator.is_main_process:\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(MODEL_SAVE_PATH + EXPERIMENT_NAME)\n",
    "\n",
    "        print('SAVING MODEL @ ',MODEL_SAVE_PATH +EXPERIMENT_NAME)\n",
    "        unwrapped_model.save_pretrained(MODEL_SAVE_PATH +EXPERIMENT_NAME)\n",
    "        print('saved')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c17257-46c0-47e1-8906-11b9ecfe0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter nbconvert --to script data_pipe.ipynb\n",
    "# accelerate launch data_pipe.py > log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7802808-ad53-44ec-9468-aff785cfa0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
