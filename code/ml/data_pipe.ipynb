{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d3e234-741d-493b-89f7-f00b39b6ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "import torch\n",
    "import multiprocessing as mp\n",
    "accelerator = Accelerator()\n",
    "accelerator.state.num_processes = 3  # For 3 GPUs\n",
    "device = accelerator.device\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a994e3c-4bb4-4196-840d-3c78c182596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys, json,re, pickle ,threading\n",
    "import magic, hashlib,  traceback ,ntpath, collections ,lief\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "import torch.nn as nn\n",
    "import lief\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from transformers import AdamW,AutoTokenizer\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score,f1_score, confusion_matrix,mean_squared_error, mean_absolute_error, r2_score\n",
    "from numpy import *\n",
    "from num2words import num2words\n",
    "import pandas as pd\n",
    "from capstone import Cs, CS_ARCH_X86, CS_MODE_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f654b05f-145b-405f-b917-6bd69545e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_FILE_TYPE = 'PE' #or ELF\n",
    "bin_path = '/home/raisul/DATA/x86_pe_msvc_O2_static/' #/home/raisul/DATA/temp/x86_pe_msvc_O2_static/'\n",
    "bin_files = [os.path.join(bin_path, f) for f in os.listdir(bin_path) if f.endswith(\".exe\")]#[:2]\n",
    "ground_truth_path ='/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/'#'/home/raisul/DATA/temp/ghidra_x86_pe_msvc_O2_debug/'  \n",
    "MODEL_SAVE_PATH= '/home/raisul/probabilistic_disassembly/models/'\n",
    "EXPERIMENT_NAME = 'prototype_pe_small'\n",
    "MAX_TOKEN_SIZE = 120\n",
    "MAX_SEQUENCE_LENGTH = 10\n",
    "VOCAB_SIZE = 500\n",
    "BATCH_SIZE = 500\n",
    "VALIDATION_DISPLAY_SIZE = 100000\n",
    "MAX_FILE_TO_USE = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af48a64-8869-4fe6-96a4-1b2f7bac5a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2886424/1340937240.py:3: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  temp_dict = {key: sum(ord(c) for c in key) % 10 for key in bin_files}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_train_test_split(bin_path):\n",
    "    bin_files = [ f for f in os.listdir(bin_path) ][0:MAX_FILE_TO_USE] #if f.endswith(\".exe\")\n",
    "    temp_dict = {key: sum(ord(c) for c in key) % 10 for key in bin_files}\n",
    "    # temp_dict = dict(sorted(temp_dict.items(), key=lambda item: item[1]))\n",
    "    dict_train = {k: v for k, v in temp_dict.items() if 0 <= v <= 7}\n",
    "    dict_test = {k: v for k, v in temp_dict.items() if 8 <= v <= 9}\n",
    "    print(len(list(dict_train.items())) ,len(list(dict_test.items())) )\n",
    "    return list(dict_train.keys()) , list(dict_test.keys())\n",
    "train_bins , test_bins = make_train_test_split(bin_path)\n",
    "\n",
    "train_bins = train_bins\n",
    "test_bins  = test_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af8e984-c7ac-4ce3-9978-2f8128e992ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_num_with_word(input_string , replace_dict):\n",
    "    def num_to_word(match):\n",
    "        number = int( match.group(0))\n",
    "        return num2words(replace_dict[number]).replace(' ','').replace('-',\"\")\n",
    "    result_string = re.sub(r'\\b\\d+\\b', num_to_word, input_string)\n",
    "    return result_string\n",
    "\n",
    "\n",
    "\n",
    "def replace_hex_with_decimal(input_string):\n",
    "    # Regular expression to find hexadecimal numbers prefixed with \"0x\" or \"0X\"\n",
    "    hex_pattern = r'0[xX][0-9a-fA-F]+'\n",
    "    \n",
    "    # Function to convert each found hex number to decimal\n",
    "    def hex_to_decimal(match):\n",
    "        hex_value = match.group(0)  # Extract the matched hex number\n",
    "        decimal_value = str(int(hex_value, 16))  # Convert hex to decimal\n",
    "        return decimal_value\n",
    "    # Substitute all hex numbers in the string with their decimal equivalents\n",
    "    result_string = re.sub(hex_pattern, hex_to_decimal, input_string)\n",
    "    return result_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d01dfce-edb1-4a0a-a0a8-fbaf3fac12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ground_truth_ghidra(exe_path, text_section_offset , text_section_len):\n",
    "\n",
    "    text_sextion_end = text_section_offset + text_section_len\n",
    "    \n",
    "    elf_file_name = os.path.basename(exe_path)\n",
    "    ghidra_file_path = os.path.join(ground_truth_path, elf_file_name.split('.')[0]) + '.json'\n",
    "    \n",
    "    with open(ghidra_file_path, \"r\") as file:\n",
    "        ghidra_data = json.load(file)\n",
    "\n",
    "    ground_truth_offsets = list(ghidra_data.keys())\n",
    "\n",
    "    ground_truth_offsets = [int(i) for i in ground_truth_offsets]\n",
    "    ground_truth_offsets = [x for x in ground_truth_offsets if text_section_offset <= x <= text_sextion_end]\n",
    "    ground_truth_offsets.sort()\n",
    "    return ground_truth_offsets\n",
    "\n",
    "\n",
    "\n",
    "def find_data_in_textsection(ground_truth_offsets , text_section_offset , text_section_len, offset_inst_dict):\n",
    "    data_offsets = []\n",
    "    for i in range(1, len(ground_truth_offsets)-1):\n",
    "        distance = ground_truth_offsets[i+1] - ground_truth_offsets[i]\n",
    "\n",
    "        inst_len = offset_inst_dict[ground_truth_offsets[i]].size \n",
    "        \n",
    "        if distance!=inst_len:\n",
    "            # print('offset_ranges[i]: ',ground_truth_offsets[i] , 'offset_ranges[i-1]: ',ground_truth_offsets[i-1], ' inst_len: ',inst_len  )\n",
    "            # print(ground_truth_offsets[i],' ' ,hex(ground_truth_offsets[i]) , offset_inst_dict[ground_truth_offsets[i]], ' len',offset_inst_dict[ground_truth_offsets[i]].size )\n",
    "            # print(\"\\nByte GAP ###### \",distance ,' Missing bytes: ', distance - inst_len)\n",
    "            \n",
    "            for j in range( ground_truth_offsets[i] +inst_len , ground_truth_offsets[i+1]  ):\n",
    "                data_offsets.append(j)\n",
    "                # if offset_inst_dict[j]:\n",
    "                #     print(\"# \",j, offset_inst_dict[j].mnemonic, offset_inst_dict[j].op_str , 'inst len:',offset_inst_dict[j].size )\n",
    "                # else:\n",
    "                #     print(\"# \",j, \" invalid \")\n",
    "            # print('\\n')\n",
    "        else:\n",
    "            # print(ground_truth_offsets[i],' ', hex(ground_truth_offsets[i]) , offset_inst_dict[ground_truth_offsets[i]].mnemonic,offset_inst_dict[ground_truth_offsets[i]].op_str ,' len',offset_inst_dict[ground_truth_offsets[i]].size)\n",
    "            pass\n",
    "    return data_offsets\n",
    "    \n",
    "\n",
    "def linear_sweep(offset_inst , target_offset):\n",
    "    inst_sequence = ''\n",
    "    address_list = []\n",
    "    \n",
    "    current_offset = target_offset\n",
    "    for q in range(MAX_SEQUENCE_LENGTH):\n",
    "\n",
    "        if current_offset in offset_inst: #if end of text section\n",
    "            current_instruction = offset_inst[current_offset]\n",
    "            if current_instruction is None:\n",
    "                return  None\n",
    "                \n",
    "            current_offset = current_offset + current_instruction.size\n",
    "            inst_sequence+= str( hex(current_instruction.address)) +\" \"+ current_instruction.mnemonic +' '+ current_instruction.op_str+ ' ; ' \n",
    "            address_list.append(current_instruction.address)\n",
    "            \n",
    "            if current_instruction.mnemonic in [\"ret\", \"jmp\"]: #break linear sweep\n",
    "                break\n",
    "                \n",
    "\n",
    "    return inst_sequence, address_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c2f8ec7-72bd-4fd8-aef3-90ef4e0fcaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def create_samples(bin_file_paths):\n",
    "\n",
    "    \n",
    "#     SEQUENCES = []\n",
    "#     LABELS     = []\n",
    "    \n",
    "#     for bin_file_path in bin_file_paths:\n",
    "    \n",
    "        \n",
    "#         md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "#         md.detail = True\n",
    "#         offset_inst = {}\n",
    "    \n",
    "#         try:\n",
    "#             with open(bin_file_path, 'rb') as f:\n",
    "    \n",
    "            \n",
    "#                 if BIN_FILE_TYPE == \"ELF\":\n",
    "#                     elffile = ELFFile(f)\n",
    "#                     textSection = elffile.get_section_by_name('.text').data()\n",
    "#                     text_section_offset = elffile.get_section_by_name('.text')['sh_offset']\n",
    "                  \n",
    "#                 elif BIN_FILE_TYPE == \"PE\":\n",
    "    \n",
    "                            \n",
    "#                     pe_file = lief.parse(bin_file_path)\n",
    "#                     text_section = pe_file.get_section(\".text\")\n",
    "#                     text_section_offset = text_section.pointerto_raw_data\n",
    "#                     textSection = bytes(text_section.content)\n",
    "                    \n",
    "#                 ground_truth_offsets = get_ground_truth_ghidra(bin_file_path, text_section_offset , len(textSection))\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(\"An error occurred:\", e ,bin_file_path)\n",
    "#             continue\n",
    "    \n",
    "#         for byte_index in range(len(textSection)):\n",
    "#             try:    \n",
    "    \n",
    "#                 instruction = next(md.disasm(textSection[byte_index: byte_index+15 ], text_section_offset + byte_index ), None)\n",
    "#                 offset_inst[text_section_offset+byte_index] = instruction\n",
    "                \n",
    "#                 # if instruction:\n",
    "#                 #     print(\"%d:\\t%s\\t%s _\\t%x\" %(int(instruction.address), instruction.mnemonic, instruction.op_str, instruction.size))\n",
    "#                 # else:\n",
    "#                 #     print(\"%d:\\t%s \" % (text_section_offset + byte_index  , 'invalid instruction') )\n",
    "                    \n",
    "                \n",
    "    \n",
    "#             except Exception as e:\n",
    "#                 print(traceback.print_exc() )\n",
    "#                 print(e)\n",
    "    \n",
    "        \n",
    "#         offset_inst_dict = collections.OrderedDict(sorted(offset_inst.items()))\n",
    "    \n",
    "#         DATA_OFFSETS = find_data_in_textsection(ground_truth_offsets , text_section_offset , len(textSection) , offset_inst)\n",
    "    \n",
    "    \n",
    "        \n",
    "#         for byte_offset in range(text_section_offset, text_section_offset+len(textSection)):\n",
    "#             return_value = linear_sweep(offset_inst_dict ,  byte_offset )\n",
    "#             if return_value== None:\n",
    "#                 continue\n",
    "#             inst_seq, inst_addresses = return_value \n",
    "#             ###################################################################\n",
    "#             ## number to words\n",
    "#             disassembly_decimal = replace_hex_with_decimal(inst_seq)\n",
    "    \n",
    "#             #num to words all\n",
    "#             numbers = [int(s) for s in re.findall(r'\\b\\d+\\b', disassembly_decimal)]\n",
    "#             numbers = sorted(set(numbers) , reverse=True)\n",
    "#             number_word_dict = {}\n",
    "            \n",
    "#             for ix,n in enumerate(numbers):\n",
    "#                 number_word_dict[n] = len(numbers)-1 -ix\n",
    "    \n",
    "#             disassembly_num_to_words = replace_num_with_word(disassembly_decimal , number_word_dict)\n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "            \n",
    "#             ###########################################################################\n",
    "            \n",
    "            \n",
    "#             SEQUENCES.append(os.path.basename(bin_file_path)+\"_\"+str(byte_offset)+\"_\"+disassembly_num_to_words ) #os.path.basename(bin_file_path)+\"_\"+str(byte_offset)+\"_\"+\n",
    "#             if byte_offset in ground_truth_offsets:\n",
    "#                 LABELS.append(float(1))\n",
    "#             else:\n",
    "#                 LABELS.append(float(0))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     #Downsample \n",
    "#     data = pd.DataFrame({\"text\": SEQUENCES, \"label\": LABELS})\n",
    "    \n",
    "#     # Split by label\n",
    "#     zeros = data[data[\"label\"] == 0]\n",
    "#     ones = data[data[\"label\"] == 1]\n",
    "    \n",
    "#     # Downsample zeros to 10%\n",
    "#     zeros_downsampled = zeros.sample(frac=0.1, random_state=42)\n",
    "    \n",
    "#     # Combine and shuffle\n",
    "#     balanced_data = pd.concat([zeros_downsampled, ones]).sample(frac=1, random_state=42)\n",
    "    \n",
    "#     # Extract final lists\n",
    "#     SEQUENCES = balanced_data[\"text\"].tolist()\n",
    "#     LABELS = balanced_data[\"label\"].tolist()\n",
    "    \n",
    "#     print(len(SEQUENCES) , len(LABELS))\n",
    "#     print(LABELS.count(0), LABELS.count(1))\n",
    "#     return SEQUENCES,LABELS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c02fbe3e-5edb-44e2-baa7-f7403885e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_bin_file(bin_file_path):\n",
    "    SEQUENCES = []\n",
    "    LABELS = []\n",
    "    \n",
    "    md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "    md.detail = True\n",
    "    offset_inst = {}\n",
    "    \n",
    "    try:\n",
    "        with open(bin_file_path, 'rb') as f:\n",
    "            if BIN_FILE_TYPE == \"ELF\":\n",
    "                elffile = ELFFile(f)\n",
    "                textSection = elffile.get_section_by_name('.text').data()\n",
    "                text_section_offset = elffile.get_section_by_name('.text')['sh_offset']\n",
    "            elif BIN_FILE_TYPE == \"PE\":\n",
    "                pe_file = lief.parse(bin_file_path)\n",
    "                text_section = pe_file.get_section(\".text\")\n",
    "                text_section_offset = text_section.pointerto_raw_data\n",
    "                textSection = bytes(text_section.content)\n",
    "            \n",
    "            ground_truth_offsets = get_ground_truth_ghidra(bin_file_path, text_section_offset, len(textSection))\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e, bin_file_path)\n",
    "        return [], []\n",
    "    \n",
    "    for byte_index in range(len(textSection)):\n",
    "        try:\n",
    "            instruction = next(md.disasm(textSection[byte_index: byte_index+15], text_section_offset + byte_index), None)\n",
    "            offset_inst[text_section_offset + byte_index] = instruction\n",
    "        except Exception as e:\n",
    "            print(traceback.print_exc())\n",
    "            print(e)\n",
    "    \n",
    "    offset_inst_dict = collections.OrderedDict(sorted(offset_inst.items()))\n",
    "    DATA_OFFSETS = find_data_in_textsection(ground_truth_offsets, text_section_offset, len(textSection), offset_inst)\n",
    "    \n",
    "    for byte_offset in range(text_section_offset, text_section_offset + len(textSection)):\n",
    "        return_value = linear_sweep(offset_inst_dict, byte_offset)\n",
    "        if return_value is None:\n",
    "            continue\n",
    "        inst_seq, inst_addresses = return_value\n",
    "        \n",
    "        disassembly_decimal = replace_hex_with_decimal(inst_seq)\n",
    "        numbers = sorted(set(int(s) for s in re.findall(r'\\b\\d+\\b', disassembly_decimal)), reverse=True)\n",
    "        number_word_dict = {n: len(numbers) - 1 - ix for ix, n in enumerate(numbers)}\n",
    "        disassembly_num_to_words = replace_num_with_word(disassembly_decimal, number_word_dict)\n",
    "        \n",
    "        # SEQUENCES.append(f\"{os.path.basename(bin_file_path)}_{byte_offset}_{disassembly_num_to_words}\")\n",
    "        SEQUENCES.append(disassembly_num_to_words)\n",
    "        LABELS.append(float(1) if byte_offset in ground_truth_offsets else float(0))\n",
    "    \n",
    "    return SEQUENCES, LABELS\n",
    "\n",
    "def create_samples(bin_file_paths):\n",
    "    with mp.Pool(processes=180) as pool:\n",
    "        results = pool.map_async(process_bin_file, bin_file_paths)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    results = results.get()  \n",
    "    SEQUENCES = [seq for result in results for seq in result[0]]\n",
    "    LABELS = [label for result in results for label in result[1]]\n",
    "    \n",
    "    data = pd.DataFrame({\"text\": SEQUENCES, \"label\": LABELS})\n",
    "    zeros = data[data[\"label\"] == 0].sample(frac=0.1, random_state=42)\n",
    "    ones = data[data[\"label\"] == 1]\n",
    "    balanced_data = pd.concat([zeros, ones]).sample(frac=1, random_state=42)\n",
    "    \n",
    "    SEQUENCES = balanced_data[\"text\"].tolist()\n",
    "    LABELS = balanced_data[\"label\"].tolist()\n",
    "\n",
    "    return SEQUENCES, LABELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5248d1e7-58fb-4c8c-9edb-8e5daa37a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_bin_file(bin_file_path, results):\n",
    "#     SEQUENCES = []\n",
    "#     LABELS = []\n",
    "    \n",
    "#     md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "#     md.detail = True\n",
    "#     offset_inst = {}\n",
    "    \n",
    "#     try:\n",
    "#         with open(bin_file_path, 'rb') as f:\n",
    "#             if BIN_FILE_TYPE == \"ELF\":\n",
    "#                 elffile = ELFFile(f)\n",
    "#                 textSection = elffile.get_section_by_name('.text').data()\n",
    "#                 text_section_offset = elffile.get_section_by_name('.text')['sh_offset']\n",
    "#             elif BIN_FILE_TYPE == \"PE\":\n",
    "#                 pe_file = lief.parse(bin_file_path)\n",
    "#                 text_section = pe_file.get_section(\".text\")\n",
    "#                 text_section_offset = text_section.pointerto_raw_data\n",
    "#                 textSection = bytes(text_section.content)\n",
    "            \n",
    "#             ground_truth_offsets = get_ground_truth_ghidra(bin_file_path, text_section_offset, len(textSection))\n",
    "#     except Exception as e:\n",
    "#         print(\"An error occurred:\", e, bin_file_path)\n",
    "#         results.append(([], []))\n",
    "#         return\n",
    "    \n",
    "#     for byte_index in range(len(textSection)):\n",
    "#         try:\n",
    "#             instruction = next(md.disasm(textSection[byte_index: byte_index+15], text_section_offset + byte_index), None)\n",
    "#             offset_inst[text_section_offset + byte_index] = instruction\n",
    "#         except Exception as e:\n",
    "#             print(traceback.print_exc())\n",
    "#             print(e)\n",
    "    \n",
    "#     offset_inst_dict = collections.OrderedDict(sorted(offset_inst.items()))\n",
    "#     DATA_OFFSETS = find_data_in_textsection(ground_truth_offsets, text_section_offset, len(textSection), offset_inst)\n",
    "    \n",
    "#     for byte_offset in range(text_section_offset, text_section_offset + len(textSection)):\n",
    "#         return_value = linear_sweep(offset_inst_dict, byte_offset)\n",
    "#         if return_value is None:\n",
    "#             continue\n",
    "#         inst_seq, inst_addresses = return_value\n",
    "        \n",
    "#         disassembly_decimal = replace_hex_with_decimal(inst_seq)\n",
    "#         numbers = sorted(set(int(s) for s in re.findall(r'\\b\\d+\\b', disassembly_decimal)), reverse=True)\n",
    "#         number_word_dict = {n: len(numbers) - 1 - ix for ix, n in enumerate(numbers)}\n",
    "#         disassembly_num_to_words = replace_num_with_word(disassembly_decimal, number_word_dict)\n",
    "        \n",
    "#         SEQUENCES.append( disassembly_num_to_words )#f\"{os.path.basename(bin_file_path)}_{byte_offset}_{disassembly_num_to_words}\")\n",
    "#         LABELS.append(float(1) if byte_offset in ground_truth_offsets else float(0))\n",
    "    \n",
    "#     results.append((SEQUENCES, LABELS))\n",
    "\n",
    "# def create_samples(bin_file_paths):\n",
    "#     threads = []\n",
    "#     results = []\n",
    "    \n",
    "#     for bin_file_path in bin_file_paths:\n",
    "#         thread = threading.Thread(target=process_bin_file, args=(bin_file_path, results))\n",
    "#         threads.append(thread)\n",
    "#         thread.start()\n",
    "    \n",
    "#     for thread in threads:\n",
    "#         thread.join()\n",
    "    \n",
    "#     SEQUENCES = [seq for result in results for seq in result[0]]\n",
    "#     LABELS = [label for result in results for label in result[1]]\n",
    "    \n",
    "#     data = pd.DataFrame({\"text\": SEQUENCES, \"label\": LABELS})\n",
    "#     zeros = data[data[\"label\"] == 0].sample(frac=0.1, random_state=42)\n",
    "#     ones = data[data[\"label\"] == 1]\n",
    "#     balanced_data = pd.concat([zeros, ones]).sample(frac=1, random_state=42)\n",
    "    \n",
    "#     SEQUENCES = balanced_data[\"text\"].tolist()\n",
    "#     LABELS = balanced_data[\"label\"].tolist()\n",
    "    \n",
    "#     print(len(SEQUENCES), len(LABELS))\n",
    "#     print(LABELS.count(0), LABELS.count(1))\n",
    "#     return SEQUENCES, LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8e9f2c-c843-4993-92de-103b371f5d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: An error occurred:[Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/ff556502c0d51a4d7f46d9408ed320a9.json'  [Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/ec768bdbfb5ade598a230b74d7719d04.json'/home/raisul/DATA/x86_pe_msvc_O2_static/ff556502c0d51a4d7f46d9408ed320a9/ff556502c0d51a4d7f46d9408ed320a9.exe \n",
      "/home/raisul/DATA/x86_pe_msvc_O2_static/ec768bdbfb5ade598a230b74d7719d04/ec768bdbfb5ade598a230b74d7719d04.exeAn error occurred:An error occurred:\n",
      "  [Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/d5788d45feae1ca9940e32a98b760dbe.json'An error occurred:[Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/ebeb0e41410caaae503317288835dce6.json'  An error occurred: /home/raisul/DATA/x86_pe_msvc_O2_static/ebeb0e41410caaae503317288835dce6/ebeb0e41410caaae503317288835dce6.exe/home/raisul/DATA/x86_pe_msvc_O2_static/d5788d45feae1ca9940e32a98b760dbe/d5788d45feae1ca9940e32a98b760dbe.exe \n",
      "[Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/e7b4e67e8cc5d8e0c3633e731ae49720.json'An error occurred:[Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/c9f10edb35933b19661c1dd385c1a807.json'\n",
      "  [Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/e9ac46732bb70f7787160b38bc357af9.json' /home/raisul/DATA/x86_pe_msvc_O2_static/e7b4e67e8cc5d8e0c3633e731ae49720/e7b4e67e8cc5d8e0c3633e731ae49720.exe\n",
      " An error occurred:/home/raisul/DATA/x86_pe_msvc_O2_static/e9ac46732bb70f7787160b38bc357af9/e9ac46732bb70f7787160b38bc357af9.exe/home/raisul/DATA/x86_pe_msvc_O2_static/c9f10edb35933b19661c1dd385c1a807/c9f10edb35933b19661c1dd385c1a807.exe\n",
      " [Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/f1d4ab4625170344c64d137aed9287d2.json'An error occurred: \n",
      "/home/raisul/DATA/x86_pe_msvc_O2_static/f1d4ab4625170344c64d137aed9287d2/f1d4ab4625170344c64d137aed9287d2.exe \n",
      "An error occurred:[Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/e0991f1917fa4889d523986f42a786c6.json'  [Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/c48361cc245a7c9eb4d2c039b5219c00.json'/home/raisul/DATA/x86_pe_msvc_O2_static/e0991f1917fa4889d523986f42a786c6/e0991f1917fa4889d523986f42a786c6.exe \n",
      "/home/raisul/DATA/x86_pe_msvc_O2_static/c48361cc245a7c9eb4d2c039b5219c00/c48361cc245a7c9eb4d2c039b5219c00.exe\n",
      "236074 236074\n",
      "An error occurred: [Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/f3c41a58591fc67d6bf2df46d215bbf0.json'An error occurred:  /home/raisul/DATA/x86_pe_msvc_O2_static/f3c41a58591fc67d6bf2df46d215bbf0/f3c41a58591fc67d6bf2df46d215bbf0.exe\n",
      "[Errno 2] No such file or directory: '/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/f2c95075ef04c7b6da27d1a92d7e5941.json' /home/raisul/DATA/x86_pe_msvc_O2_static/f2c95075ef04c7b6da27d1a92d7e5941/f2c95075ef04c7b6da27d1a92d7e5941.exe\n",
      "67647 67647\n"
     ]
    }
   ],
   "source": [
    "train_bin_paths       = [ os.path.join(os.path.join(bin_path, f),f+'.exe' )  for f in train_bins]\n",
    "validation_bin_paths  = [ os.path.join(os.path.join(bin_path, f),f+'.exe' )  for f in test_bins ]\n",
    "train_sequences, train_labels = create_samples(train_bin_paths)\n",
    "print(len(train_sequences), len(train_labels) )\n",
    "validation_sequences, validation_labels  = create_samples(validation_bin_paths)\n",
    "print(len(validation_sequences), len(validation_labels) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e0da24-481e-423d-aa66-07465ec4fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "pkl_data_save_path = MODEL_SAVE_PATH+'training_data_pe'+str(MAX_FILE_TO_USE)+'.ignore.pkl'\n",
    "with open(pkl_data_save_path , 'wb') as f:\n",
    "    pickle.dump([train_sequences,train_labels,validation_sequences, validation_labels], f)\n",
    "with open(pkl_data_save_path, \"rb\") as f:\n",
    "    train_sequences,train_labels,validation_sequences, validation_labels = pickle.load(f)\n",
    "print('saved '*1000)\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28176656-c7b2-4fad-a962-0f2b8963c5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  >  five mov byte ptr [rsp + rbp + two], al ; six mov rbp, rbx ; seven mov rdi, qword ptr [rsp + three] ; eight lea rbx, [rbx*one + zero] ; nine jmp four ;  \n",
      "\n",
      "1.0  >  zero jmp qword ptr [rip + one] ;  \n",
      "\n",
      "1.0  >  three movzx ecx, byte ptr [rbx] ; four lea rbx, [rbx + zero] ; five mov byte ptr [rax], cl ; six lea rax, [rax + zero] ; seven test cl, cl ; eight jne three ; nine mov r8, qword ptr [rdi] ; ten mov edx, two ; eleven mov rcx, qword ptr [rdi + one] ; twelve call thirteen ;  \n",
      "\n",
      "1.0  >  one call zero ; two test al, al ; three je six ; four mov rcx, qword ptr [rbx] ; five call fourteen ; six call eleven ; seven mov rdi, rax ; eight call thirteen ; nine mov rbx, qword ptr [rax] ; ten call twelve ;  \n",
      "\n",
      "1.0  >  five mov dword ptr [rsp + zero], ecx ; six sub rsp, two ; seven mov ecx, one ; eight call qword ptr [rip + sixteen] ; nine test eax, eax ; ten je fourteen ; eleven mov eax, dword ptr [rsp + four] ; twelve mov ecx, eax ; thirteen int three ; fourteen lea rcx, [rip + fifteen] ;  \n",
      "\n",
      "0.0  >  three rol dword ptr [rax + fourteen], zero ; four rol bl, one ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ; ten mov rcx, qword ptr [rip + thirteen] ; eleven lea rdx, [rip - two] ; twelve xor eax, eax ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "1.0  >  zero call eleven ; one test eax, eax ; two jne seven ; three lea rcx, [rip + twelve] ; four call eleven ; five test eax, eax ; six je nine ; seven xor al, al ; eight jmp ten ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  five mov ecx, dword ptr [rsp + four] ; six mov rbx, qword ptr [rsp + one] ; seven mov rbp, qword ptr [rsp + two] ; eight mov rsi, qword ptr [rsp + three] ; nine add rsp, zero ; ten pop rdi ; eleven jmp twelve ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  five call qword ptr [rip + fifteen] ; six test eax, eax ; seven jne twelve ; eight cmp ebx, zero ; nine je twelve ; ten lea ecx, [rax + one] ; eleven call two ; twelve mov rbx, qword ptr [rsp + four] ; thirteen add rsp, three ; fourteen pop rbp ;  \n",
      "\n",
      "1.0  >  zero jmp qword ptr [rip + one] ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  six add byte ptr [rax - five], cl ; seven add eax, eighteen ; eight mov dword ptr [rip + seventeen], nineteen ; nine mov dword ptr [rip + sixteen], one ; ten cmp dword ptr [rsp + three], zero ; eleven jbe fifteen ; twelve cmp qword ptr [rsp + four], zero ; thirteen jne fifteen ; fourteen mov dword ptr [rsp + three], zero ; fifteen cmp dword ptr [rsp + three], two ;  \n",
      "\n",
      "1.0  >  two mov esi, r9d ; three mov r10d, r9d ; four mov r11d, r9d ; five cmp r14d, zero ; six jl twelve ; seven lea eax, [r9 + zero] ; eight xor ecx, ecx ; nine cpuid  ; ten mov dword ptr [rbp - one], eax ; eleven mov esi, edx ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one ret  ;  \n",
      "\n",
      "1.0  >  zero ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero jmp qword ptr [rip + one] ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "1.0  >  one sbb eax, eax ; two neg eax ; three dec eax ; four add rsp, zero ; five ret  ;  \n",
      "\n",
      "1.0  >  four je seven ; five test dl, dl ; six jne ten ; seven call three ; eight mov cl, bl ; nine call two ; ten mov al, zero ; eleven add rsp, one ; twelve pop rbx ; thirteen ret  ;  \n",
      "\n",
      "1.0  >  three lea rdx, [rip - fourteen] ; four add rcx, rdx ; five cmp dword ptr [rcx], fifteen ; six jne thirteen ; seven mov eax, two ; eight cmp word ptr [rcx + one], ax ; nine jne thirteen ; ten sub r8, rdx ; eleven movzx edx, word ptr [rcx + zero] ; twelve add rdx, one ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero xor eax, eax ; one ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero ret  ;  \n",
      "\n",
      "1.0  >  two mov dword ptr [rip + sixteen], zero ; three mov dword ptr [rip + fifteen], eax ; four mov ecx, seventeen ; five mov rax, qword ptr [rip + fourteen] ; six and r9d, ecx ; seven and rax, eighteen ; eight mov qword ptr [rip + thirteen], rax ; nine cmp r9d, ecx ; ten jne twelve ; eleven mov rax, qword ptr [rbp + one] ;  \n",
      "\n",
      "1.0  >  three mov eax, dword ptr [r9 + zero] ; four add eax, ecx ; five cmp rdx, rax ; six jb twelve ; seven add r9, one ; eight cmp r9, r8 ; nine jne two ; ten xor eax, eax ; eleven ret  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "1.0  >  two cmp rax, zero ; three jne seven ; four lea rcx, [rip + nine] ; five call one ; six jmp eight ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero sub ebx, eax ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two mov ecx, r11d ; three mov eax, r11d ; four shr rcx, one ; five and eax, fifteen ; six and ecx, zero ; seven mov dword ptr [rip + fourteen], eax ; eight or rcx, sixteen ; nine not rcx ; ten and rcx, qword ptr [rip + thirteen] ; eleven mov qword ptr [rip + twelve], rcx ;  \n",
      "\n",
      "1.0  >  four mov rbx, qword ptr [rcx] ; five mov rdi, rcx ; six cmp dword ptr [rbx], seventeen ; seven jne fourteen ; eight cmp dword ptr [rbx + two], one ; nine jne fourteen ; ten mov edx, dword ptr [rbx + three] ; eleven lea eax, [rdx - sixteen] ; twelve cmp eax, zero ; thirteen jbe fifteen ;  \n",
      "\n",
      "1.0  >  one mov rax, qword ptr [rip + seven] ; two test rax, rax ; three je five ; four call qword ptr [rip + eight] ; five add rsp, zero ; six ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  five jbe eight ; six and rcx, seventeen ; seven mov qword ptr [rip + sixteen], rcx ; eight bt r10d, two ; nine jae fourteen ; ten mov rax, qword ptr [rbp + three] ; eleven bt rax, one ; twelve jae fourteen ; thirteen btr qword ptr [rip + fifteen], zero ; fourteen mov rbx, qword ptr [rsp + four] ;  \n",
      "\n",
      "1.0  >  zero xor eax, eax ; one cmp rcx, rdx ; two setbe al ; three ret  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "1.0  >  one mov al, zero ; two ret  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one jne eight ; two mov rax, qword ptr [rip + twelve] ; three or dword ptr [rip + thirteen], zero ; four and rax, fourteen ; five mov dword ptr [rip + eleven], ebx ; six mov qword ptr [rip + ten], rax ; seven jmp nine ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one test eax, eax ; two je five ; three call zero ; four jmp six ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two and rax, rcx ; three movabs rcx, fourteen ; four cmp rax, rbx ; five cmove rax, rcx ; six mov qword ptr [rip + twelve], rax ; seven mov rbx, qword ptr [rsp + one] ; eight not rax ; nine mov qword ptr [rip + thirteen], rax ; ten add rsp, zero ; eleven pop rbp ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  four mov dword ptr [rbp - three], eax ; five xor r9d, seventeen ; six mov dword ptr [rbp - two], ebx ; seven or r10d, r9d ; eight mov dword ptr [rbp - one], ecx ; nine mov edi, ecx ; ten mov dword ptr [rbp - zero], edx ; eleven jne fourteen ; twelve or qword ptr [rip + fifteen], eighteen ; thirteen and eax, sixteen ;  \n",
      "\n",
      "1.0  >  three mov qword ptr [rip + fourteen], rax ; four mov dword ptr [rip + fifteen], ebx ; five bt edi, zero ; six jae thirteen ; seven xor ecx, ecx ; eight xgetbv  ; nine shl rdx, two ; ten or rdx, rax ; eleven mov qword ptr [rbp + two], rdx ; twelve bt edi, one ;  \n",
      "\n",
      "0.0  >  three add byte ptr [rax], al ; four call qword ptr [rip + thirteen] ; five mov r8, qword ptr [r15 + one] ; six lea rdx, [rip + twelve] ; seven mov rcx, rax ; eight call two ; nine mov eax, zero ; ten jmp eleven ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "1.0  >  six jl sixteen ; seven mov qword ptr [rsp + three], rbx ; eight mov qword ptr [rsp + four], rbp ; nine mov qword ptr [rsp + five], rsi ; ten mov qword ptr [rsp + two], rdi ; eleven mov qword ptr [rsp + one], r15 ; twelve lea r15, [rip + seventeen] ; thirteen movaps xmmword ptr [rsp + zero], xmm6 ; fourteen movsd xmm6, qword ptr [rip + eighteen] ; fifteen nop  ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "0.0  >  zero ja one ; one add bh, bh ; two and eax, five ; three jmp qword ptr [rip + four] ;  \n",
      "\n",
      "1.0  >  two call one ; three mov ecx, eax ; four add rsp, zero ; five jmp six ;  \n",
      "\n",
      "1.0  >  zero jmp one ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two call one ; three test eax, eax ; four jne twelve ; five cmp ebx, zero ; six jne twelve ; seven mov r8, rsi ; eight xor edx, edx ; nine mov rcx, rbp ; ten mov rax, rdi ; eleven call qword ptr [rip + thirteen] ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one jmp zero ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  three mov r8d, zero ; four lea rcx, [rip + nine] ; five call two ; six xor eax, eax ; seven add rsp, one ; eight ret  ;  \n",
      "\n",
      "1.0  >  three lea rcx, [rbp + one] ; four xor qword ptr [rbp - zero], rax ; five call qword ptr [rip + thirteen] ; six mov eax, dword ptr [rbp + one] ; seven lea rcx, [rbp - zero] ; eight shl rax, two ; nine xor rax, qword ptr [rbp + one] ; ten xor rax, qword ptr [rbp - zero] ; eleven xor rax, rcx ; twelve movabs rcx, fourteen ;  \n",
      "\n",
      "0.0  >  two add byte ptr [rax], zero ; three add dword ptr [rax], eax ; four add byte ptr [rax], al ; five mov r15d, r9d ; six mov dword ptr [rip + fourteen], one ; seven mov r13d, r8d ; eight mov dword ptr [rip + thirteen], one ; nine lea rdx, [rip + twelve] ; ten nop dword ptr [rax + rax] ; eleven test ebx, ebx ;  \n",
      "\n",
      "1.0  >  zero xor al, al ; one jmp two ;  \n",
      "\n",
      "1.0  >  zero jmp qword ptr [rip + one] ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one sub rsp, zero ; two mov r8, rcx ; three mov eax, sixteen ; four cmp word ptr [rip - thirteen], ax ; five jne eleven ; six movsxd rcx, dword ptr [rip - twelve] ; seven lea rdx, [rip - fourteen] ; eight add rcx, rdx ; nine cmp dword ptr [rcx], fifteen ; ten jne eleven ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  two call one ; three mov ecx, eax ; four add rsp, zero ; five jmp six ;  \n",
      "\n",
      "1.0  >  two mov rsi, qword ptr [rsp + one] ; three add rsp, zero ; four pop rdi ; five ret  ;  \n",
      "\n",
      "1.0  >  two push r13 ; three push r14 ; four push r15 ; five sub rsp, one ; six mov r15, rcx ; seven mov r12, rdx ; eight mov ecx, zero ; nine call qword ptr [rip + twelve] ; ten mov ecx, zero ; eleven mov rbp, rax ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  one mov al, zero ; two ret  ;  \n",
      "\n",
      "0.0  >  zero add cl, ch ; one sbb ecx, dword ptr [rdi] ; two add byte ptr [rax], al ; three jmp four ;  \n",
      "\n",
      "0.0  >  zero int3  ; one int3  ; two int3  ; three int3  ; four int3  ; five int3  ; six int3  ; seven int3  ; eight int3  ; nine int3  ;  \n",
      "\n",
      "1.0  >  zero ret  ;  \n",
      "\n",
      "1.0  >  five mov qword ptr [r11 + zero], rbp ; six mov qword ptr [r11 + one], rsi ; seven mov qword ptr [r11 - two], r14 ; eight nop dword ptr [rax] ; nine cmp rdi, three ; ten jae fifteen ; eleven movzx eax, byte ptr [r12 + r9] ; twelve mov byte ptr [rsp + rdi + one], al ; thirteen mov rdi, qword ptr [rsp + four] ; fourteen inc rdi ;  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for j in range(100):\n",
    "    if True:#'int3' in SEQUENCES[j]: #LABELS[j] :\n",
    "        print(train_labels[j] , ' > ' , train_sequences[j] ,'\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085fe09-aecf-49e1-b145-acea85d14365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0307133-f04b-43dc-b48f-1a71d755ce83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "from transformers import BertTokenizer,BertForSequenceClassification\n",
    "\n",
    "# If using a character-level tokenizer for sequences like DNA/Protein:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")#BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer.train_new_from_iterator(train_sequences, VOCAB_SIZE)\n",
    "\n",
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     'bert-base-uncased',\n",
    "#     num_labels=1  \n",
    "# )\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_SAVE_PATH +EXPERIMENT_NAME,\n",
    "    num_labels=1  \n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(VOCAB_SIZE)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optim = AdamW( model.parameters() , lr=1e-5, eps = 1e-6, betas=(0.9,0.98), weight_decay=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b4129cd-e356-4327-9e23-72beed13b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        # Tokenize the \n",
    "        tokenized_text = (self.tokenizer(text , max_length= MAX_TOKEN_SIZE,padding='max_length', truncation=True , return_tensors='pt')).to(device)\n",
    "        \n",
    "        return tokenized_text, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa283cd-ae7b-4b14-aef8-d197ca0ad338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = BinaryDataset(SEQUENCES, LABELS,tokenizer)\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# validation_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset  =  BinaryDataset(train_sequences, train_labels,tokenizer)#torch.utils.data.Subset(dataset, range(train_size))\n",
    "validation_dataset = BinaryDataset(validation_sequences, validation_labels,tokenizer) #torch.utils.data.Subset(dataset, range(train_size , len(dataset)))\n",
    "\n",
    "\n",
    "# train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size] , generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f4ecfe2-f33d-42e8-aba0-f9e506fd401c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236074, 67647)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(train_dataset) , len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c119b9-3fb7-4264-be17-e50d77f81283",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE ,shuffle=False) \n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f3296ff-458f-48d5-be35-85e6dcd7a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optim, train_loader,validation_loader = accelerator.prepare(model, optim, train_loader,validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fff2a619-6a06-4774-8ec7-bad9a55e8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model ,data_loop, is_training = False):\n",
    "    \n",
    "    prediction_s, ground_truth_s = [], []\n",
    "    losses = []\n",
    "\n",
    "    for N,batch in enumerate(data_loop):\n",
    "        # Forward pass\n",
    "        if is_training == True:\n",
    "            optim.zero_grad()\n",
    "        \n",
    "        batch_input, batch_labels = batch\n",
    "        if len(batch_labels)<BATCH_SIZE:\n",
    "            continue\n",
    "            \n",
    "        batch_input_ids= batch_input['input_ids']\n",
    "        batch_attention_mask=batch_input['attention_mask']\n",
    "        batch_token_type_ids =batch_input['token_type_ids']\n",
    "        \n",
    "        outputs = model(input_ids=batch_input_ids.squeeze(),\n",
    "                        attention_mask=batch_attention_mask.squeeze(),\n",
    "                        token_type_ids=batch_token_type_ids.squeeze(),\n",
    "                        labels=batch_labels.float() )\n",
    "        \n",
    "#\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        predictions = logits.squeeze()\n",
    "        # print(logits ,predictions )\n",
    "\n",
    "        prediction_s.extend(predictions.detach().cpu().numpy().flatten())\n",
    "        ground_truth_s.extend(batch_labels.detach().cpu().numpy().flatten())\n",
    "\n",
    "\n",
    "        if is_training == True:\n",
    "            # loss.backward()\n",
    "            accelerator.backward(loss)\n",
    "            optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        data_loop.set_description(f'Epoch {ecpoch}')\n",
    "        data_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Evaluation Metrics\n",
    "    mse = mean_squared_error(ground_truth_s, prediction_s)\n",
    "    rmse = sqrt(mse)\n",
    "    mae = mean_absolute_error(ground_truth_s, prediction_s)\n",
    "    r2 = r2_score(ground_truth_s, prediction_s)\n",
    "    \n",
    "\n",
    "    metrices = {'MSE':mse ,\n",
    "                      'RMSE':rmse, \n",
    "                      'MAE':mae, \n",
    "                      'R':r2,\n",
    "                      'loss': (sum(losses) / len(losses))}\n",
    "    return metrices , prediction_s, ground_truth_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fd188e0-a6f3-4f5f-b9a6-5a9040dd42e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18%|    | 25/136 [00:14<01:05,  1.68it/s, loss=0.102]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     18\u001b[0m validation_loop \u001b[38;5;241m=\u001b[39m tqdm(validation_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m v_metrices, v_prediction_s, v_ground_truth_s  \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m demo_len \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(minimum(demo_len , \u001b[38;5;28mlen\u001b[39m(v_prediction_s) )):\n",
      "Cell \u001b[0;32mIn[19], line 27\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, data_loop, is_training)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 27\u001b[0m         losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m         logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     30\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "global_metrices = []\n",
    "v_global_metrices = []\n",
    "\n",
    "\n",
    "for ecpoch in range(EPOCHS):\n",
    "    \n",
    "    # train_loop = tqdm(train_loader, leave=True)\n",
    "    # model.train()\n",
    "    # metrices,prediction_s, ground_truth_s  = training_loop(model ,train_loop, is_training = True)\n",
    "    # global_metrices.append(metrices)\n",
    "    # print(\"Training metrices \",metrices)\n",
    "     \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        validation_loop = tqdm(validation_loader, leave=True)\n",
    "        v_metrices, v_prediction_s, v_ground_truth_s  = training_loop(model ,validation_loop, is_training = False)\n",
    "\n",
    "\n",
    "        demo_len =10000\n",
    "        for i in range(minimum(demo_len , len(v_prediction_s) )):\n",
    "\n",
    "            print('\\n')\n",
    "            sequence_text = validation_sequences[ i ]\n",
    "            print( v_prediction_s[i], v_ground_truth_s[i] , '\\n' , sequence_text)\n",
    "\n",
    "\n",
    "           \n",
    "        print( 'v_metrices: ',v_metrices )\n",
    "        v_global_metrices.append(v_metrices)\n",
    "        \n",
    "    if accelerator.is_main_process:\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(MODEL_SAVE_PATH + EXPERIMENT_NAME)\n",
    "\n",
    "        print('SAVING MODEL @ ',MODEL_SAVE_PATH +EXPERIMENT_NAME)\n",
    "        unwrapped_model.save_pretrained(MODEL_SAVE_PATH +EXPERIMENT_NAME)\n",
    "        print('saved')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c17257-46c0-47e1-8906-11b9ecfe0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter nbconvert --to script data_pipe.ipynb\n",
    "# accelerate launch data_pipe.py > log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7802808-ad53-44ec-9468-aff785cfa0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b5176-9b8e-4308-a725-50f1aec0b085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
