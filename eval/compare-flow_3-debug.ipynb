{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48522cc8-2717-4417-a1de-7e8b7b7168db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys, json,re, pickle\n",
    "import magic, hashlib,  traceback ,ntpath, collections ,lief\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "import torch.nn as nn\n",
    "import lief\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from transformers import AdamW,AutoTokenizer\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score,f1_score, confusion_matrix,mean_squared_error, mean_absolute_error, r2_score\n",
    "from numpy import *\n",
    "from num2words import num2words\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc760d6-af81-4d91-b02b-c6dc92cc8560",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_json_dir = \"/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/\"\n",
    "#   \n",
    "predict_json_dir_1 = \"/home/raisul/ANALYSED_DATA/test/x86_pe_msvc_O2_static_1k_prob_disasm_4/\"  #'/home/raisul/ANALYSED_DATA/prob_disasm_x86_pe_msvc_O2_static/'\n",
    "predict_json_dir_2 = \"/home/raisul/ANALYSED_DATA/test/x86_pe_msvc_O2_static_1k_prob_disasm/\"\n",
    "BIN_FILE_TYPE = \"PE\"\n",
    "BIN_PATH = \"/home/raisul/DATA/x86_pe_msvc_O2_static_stripped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc8e3a2-a078-4145-97e7-47bd15a5d70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "\n",
      "true_positive_1:  1512 \n",
      " false_positive_1:  19843 \n",
      "false_negative_1: 116 \n",
      "true_negative_1:  33\n",
      "\n",
      "true_positive_2:  1628 \n",
      " false_positive_2:  133 \n",
      "false_negative_2: 0 \n",
      "true_negative_2:  15516\n",
      "\n",
      "true_positive_1:  1640 \n",
      " false_positive_1:  20747 \n",
      "false_negative_1: 114 \n",
      "true_negative_1:  27\n",
      "\n",
      "true_positive_2:  1754 \n",
      " false_positive_2:  277 \n",
      "false_negative_2: 0 \n",
      "true_negative_2:  16134\n",
      "\n",
      "true_positive_1:  1325 \n",
      " false_positive_1:  19046 \n",
      "false_negative_1: 87 \n",
      "true_negative_1:  22\n",
      "\n",
      "true_positive_2:  1412 \n",
      " false_positive_2:  229 \n",
      "false_negative_2: 0 \n",
      "true_negative_2:  14516\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_offsets(json_file_path):\n",
    "    with open(json_file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        temp = []\n",
    "        for key,val in data.items():\n",
    "            if 'int3' not in val.lower() and 'nop' not in val.lower():\n",
    "                temp.append(int(key))\n",
    "    return temp\n",
    "\n",
    "\n",
    "\n",
    "def get_instructions(bin_file_path  ):\n",
    "    md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "    md.detail = True\n",
    "    offset_inst = {}\n",
    "\n",
    "    with open(bin_file_path, 'rb') as f:\n",
    "        try:\n",
    "            if BIN_FILE_TYPE == \"ELF\":\n",
    "                elffile = ELFFile(f)\n",
    "                textSection = elffile.get_section_by_name('.text').data()\n",
    "                text_section_offset = elffile.get_section_by_name('.text')['sh_offset']\n",
    "              \n",
    "            elif BIN_FILE_TYPE == \"PE\":\n",
    "        \n",
    "                        \n",
    "                pe_file = lief.parse(bin_file_path)\n",
    "                text_section = pe_file.get_section(\".text\")\n",
    "                text_section_offset = text_section.pointerto_raw_data\n",
    "                textSection = bytes(text_section.content)\n",
    "                \n",
    "        except Exception as e:\n",
    "                print(\"An error occurred:\", e ,bin_file_path)\n",
    "                return\n",
    "    \n",
    "        for byte_index in range(len(textSection)):\n",
    "            try:    \n",
    "    \n",
    "                instruction = next(md.disasm(textSection[byte_index: byte_index+15 ], text_section_offset + byte_index ), None)\n",
    "                offset_inst[text_section_offset+byte_index] = instruction\n",
    "                \n",
    "                # if instruction:\n",
    "                #     print(\"%d:\\t%s\\t%s _\\t%x\" %(int(instruction.address), instruction.mnemonic, instruction.op_str, instruction.size))\n",
    "                # else:\n",
    "                #     print(\"%d:\\t%s \" % (text_section_offset + byte_index  , 'invalid instruction') )\n",
    "    \n",
    "            except Exception as e:\n",
    "                print(traceback.print_exc() )\n",
    "                print(e)\n",
    "    return offset_inst\n",
    "\n",
    "ground_truth__jsons  =  os.listdir(ground_truth_json_dir) \n",
    "predict_jsons1    =  os.listdir(predict_json_dir_1)\n",
    "predict_jsons2 = os.listdir(predict_json_dir_2)\n",
    "\n",
    "common_json_files = list(set(ground_truth__jsons) & set(predict_jsons1) & set(predict_jsons2))\n",
    "print(len(common_json_files))\n",
    "common_json_files = common_json_files[0:10]\n",
    "# common_json_files =['370cf902ac71f426c14725a24959e8de.json']\n",
    "all_TP_1= all_FP_1= all_FN_1= all_TN_1 = 0\n",
    "all_TP_2= all_FP_2= all_FN_2= all_TN_2 = 0\n",
    "\n",
    "for json_file_name in common_json_files:\n",
    "    # print('\\n\\n\\n',json_file_name)\n",
    "    ground_truth_json_path =  os.path.join(ground_truth_json_dir, json_file_name)\n",
    "    predict_json_path_1 =  os.path.join(predict_json_dir_1, json_file_name)\n",
    "    predict_json_path_2 =  os.path.join(predict_json_dir_2, json_file_name)\n",
    "    \n",
    "    ground_truth_offsets = get_offsets(ground_truth_json_path)\n",
    "    predict_offsets_1 = get_offsets(predict_json_path_1)\n",
    "    predict_offsets_2 = get_offsets(predict_json_path_2)\n",
    "    \n",
    "    ground_truth_offsets_set = set(ground_truth_offsets)\n",
    "    predict_offsets_set_1 = set(predict_offsets_1)\n",
    "    predict_offsets_set_2 = set(predict_offsets_2)\n",
    "\n",
    "    \n",
    "    superset = set(range( min(ground_truth_offsets) , max(ground_truth_offsets) ) )\n",
    "    \n",
    "    true_positive_1 = len(ground_truth_offsets_set&predict_offsets_set_1)\n",
    "    false_positive_1 = len(predict_offsets_set_1 - ground_truth_offsets_set)\n",
    "    false_negative_1 = len( ground_truth_offsets_set -predict_offsets_set_1 )\n",
    "    true_negative_1 = len( superset - ( ground_truth_offsets_set|predict_offsets_set_1)  )\n",
    "\n",
    "    true_positive_2 = len(ground_truth_offsets_set&predict_offsets_set_2)\n",
    "    false_positive_2 = len(predict_offsets_set_2 - ground_truth_offsets_set)\n",
    "    false_negative_2 = len( ground_truth_offsets_set -predict_offsets_set_2 )\n",
    "    true_negative_2 = len( superset - ( ground_truth_offsets_set|predict_offsets_set_2)  )\n",
    "    \n",
    "    all_TP_1+=true_positive_1\n",
    "    all_FP_1+=false_positive_1\n",
    "    all_FN_1+=false_negative_1\n",
    "    all_TN_1+=true_negative_1\n",
    "\n",
    "    all_TP_2+=true_positive_2\n",
    "    all_FP_2+=false_positive_2\n",
    "    all_FN_2+=false_negative_2\n",
    "    all_TN_2+=true_negative_2\n",
    "    \n",
    "    print('\\ntrue_positive_1: ',true_positive_1 , '\\n false_positive_1: ',false_positive_1 ,'\\nfalse_negative_1:', false_negative_1 , '\\ntrue_negative_1: ',true_negative_1)\n",
    "    print('\\ntrue_positive_2: ',true_positive_2 , '\\n false_positive_2: ',false_positive_2 ,'\\nfalse_negative_2:', false_negative_2 , '\\ntrue_negative_2: ',true_negative_2)\n",
    "\n",
    "    continue\n",
    "    \n",
    "    bin_file_path = os.path.join(os.path.join(BIN_PATH ,  json_file_name.split('.')[0] ),  (json_file_name.split('.')[0]+ ('.exe' if BIN_FILE_TYPE == \"PE\" else '' )))\n",
    "    exhaustive_disasm = get_instructions(bin_file_path)\n",
    "    # print(exhaustive_disasm)\n",
    "    if exhaustive_disasm:\n",
    "      for offset in exhaustive_disasm:\n",
    "          if exhaustive_disasm[offset] is None:\n",
    "              continue\n",
    "          hash = '#' if offset in ground_truth_offsets else ' '\n",
    "          dollar = '$' if offset in predict_offsets_set_1 else ' '\n",
    "          star = '*' if offset in predict_offsets_set_2 else ' '\n",
    "          marker = ''\n",
    "          if offset in predict_offsets_set_2 and offset not in predict_offsets_set_1 :# \n",
    "              # 1 = isasm_4/\"  \n",
    "              marker = '     >>>>>>>>      '*3\n",
    "          if hash=='#' or dollar=='$' or star=='*':\n",
    "              print( hash , dollar ,star, hex(offset), exhaustive_disasm[offset].mnemonic+ exhaustive_disasm[offset].op_str ,' ', exhaustive_disasm[offset].size,marker) \n",
    "          \n",
    "\n",
    "    else:\n",
    "        print('exhaustive diasm none')\n",
    "    # print(len(ground_truth_offsets) , len(predict_offsets))\n",
    "    # false_negatives = list(set(ground_truth_offsets) - set(predict_offsets))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4a451e-21a5-4815-8506-3e183348d7cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3976145860.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    false_positive_1:  277\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "true_positive_1:  1748 \n",
    " false_positive_1:  277 \n",
    "false_negative_1: 6 \n",
    "true_negative_1:  16134\n",
    "\n",
    "true_positive_2:  1754 \n",
    " false_positive_2:  277 \n",
    "false_negative_2: 0 \n",
    "true_negative_2:  16134\n",
    "\n",
    "true_positive_1:  1409 \n",
    " false_positive_1:  229 \n",
    "false_negative_1: 3 \n",
    "true_negative_1:  14516\n",
    "\n",
    "true_positive_2:  1412 \n",
    " false_positive_2:  229 \n",
    "false_negative_2: 0 \n",
    "true_negative_2:  14516\n",
    "\n",
    "true_positive_1:  1625 \n",
    " false_positive_1:  133 \n",
    "false_negative_1: 3 \n",
    "true_negative_1:  15516\n",
    "\n",
    "true_positive_2:  1628 \n",
    " false_positive_2:  133 \n",
    "false_negative_2: 0 \n",
    "true_negative_2:  15516\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586aaf9-0da5-4fdd-a383-2a3f094855e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rue_positive_1:  1140 \n",
    " false_positive_1:  1674 \n",
    "false_negative_1: 272 \n",
    "true_negative_1:  12855\n",
    "\n",
    "true_positive_2:  1412 \n",
    " false_positive_2:  229 \n",
    "false_negative_2: 0 \n",
    "true_negative_2:  14516\n",
    "\n",
    "true_positive_1:  1313 \n",
    " false_positive_1:  2238 \n",
    "false_negative_1: 315 \n",
    "true_negative_1:  13291\n",
    "\n",
    "true_positive_2:  1628 \n",
    " false_positive_2:  133 \n",
    "false_negative_2: 0 \n",
    "true_negative_2:  15516\n",
    "\n",
    "true_positive_1:  1472 \n",
    " false_positive_1:  2305 \n",
    "false_negative_1: 282 \n",
    "true_negative_1:  13850\n",
    "\n",
    "true_positive_2:  1754 \n",
    " false_positive_2:  277 \n",
    "false_negative_2: 0 \n",
    "true_negative_2:  16134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ea1f7-3173-437a-b4a8-0771b8b9ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "279/ (279+ 1754) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d363a5-27e4-4173-aedc-78bfb3114749",
   "metadata": {},
   "outputs": [],
   "source": [
    "how to truncate a float between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f495a8-f841-41c4-853b-19c224eb6087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
