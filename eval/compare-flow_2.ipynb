{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48522cc8-2717-4417-a1de-7e8b7b7168db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys, json,re, pickle\n",
    "import magic, hashlib,  traceback ,ntpath, collections ,lief\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "import torch.nn as nn\n",
    "import lief\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from transformers import AdamW,AutoTokenizer\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score,f1_score, confusion_matrix,mean_squared_error, mean_absolute_error, r2_score\n",
    "from numpy import *\n",
    "from num2words import num2words\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc760d6-af81-4d91-b02b-c6dc92cc8560",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_json_dir = \"/home/raisul/ANALYSED_DATA/ghidra_x86_pe_msvc_O2_static/\"\n",
    "#   \n",
    "predict_json_dir = \"/home/raisul/ANALYSED_DATA/test/x86_pe_msvc_O2_static_1k_prob_disasm_4/\"  #'/home/raisul/ANALYSED_DATA/prob_disasm_x86_pe_msvc_O2_static/'\n",
    "BIN_FILE_TYPE = \"PE\"\n",
    "BIN_PATH = \"/home/raisul/DATA/x86_pe_msvc_O2_static_stripped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc8e3a2-a078-4145-97e7-47bd15a5d70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "\n",
      "true_positive:  1389 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14427\n",
      "\n",
      "true_positive:  1739 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  16101\n",
      "\n",
      "true_positive:  1698 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  15918\n",
      "\n",
      "true_positive:  1754 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  16134\n",
      "\n",
      "true_positive:  1367 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14305\n",
      "\n",
      "true_positive:  1676 \n",
      " false_positive:  41 \n",
      "false_negative: 0 \n",
      "true_negative:  15872\n",
      "\n",
      "true_positive:  1938 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  16566\n",
      "\n",
      "true_positive:  1412 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14516\n",
      "\n",
      "true_positive:  1371 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14365\n",
      "\n",
      "true_positive:  1624 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  15608\n",
      "\n",
      "true_positive:  1762 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  16302\n",
      "\n",
      "true_positive:  1362 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14294\n",
      "\n",
      "true_positive:  1435 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14653\n",
      "\n",
      "true_positive:  2036 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  17100\n",
      "\n",
      "true_positive:  1407 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14489\n",
      "\n",
      "true_positive:  1634 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  15630\n",
      "\n",
      "true_positive:  1348 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14228\n",
      "\n",
      "true_positive:  1292 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  13996\n",
      "\n",
      "true_positive:  1886 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  16994\n",
      "\n",
      "true_positive:  1419 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14445\n",
      "\n",
      "true_positive:  1616 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  15584\n",
      "\n",
      "true_positive:  1619 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  15501\n",
      "\n",
      "true_positive:  1347 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14229\n",
      "\n",
      "true_positive:  1689 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  15927\n",
      "\n",
      "true_positive:  1625 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  15439\n",
      "\n",
      "true_positive:  1953 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  16847\n",
      "\n",
      "true_positive:  1430 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14626\n",
      "\n",
      "true_positive:  1736 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  16088\n",
      "\n",
      "true_positive:  1487 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14873\n",
      "\n",
      "true_positive:  1401 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14495\n",
      "\n",
      "true_positive:  1628 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  15516\n",
      "\n",
      "true_positive:  2165 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  17627\n",
      "\n",
      "true_positive:  1472 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14776\n",
      "\n",
      "true_positive:  1369 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14383\n",
      "\n",
      "true_positive:  1419 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  14541\n",
      "\n",
      "true_positive:  1834 \n",
      " false_positive:  21 \n",
      "false_negative: 0 \n",
      "true_negative:  16422\n",
      "\n",
      "true_positive:  1603 \n",
      " false_positive:  13 \n",
      "false_negative: 0 \n",
      "true_negative:  15221\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_offsets(json_file_path):\n",
    "    with open(json_file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        temp = []\n",
    "        for key,val in data.items():\n",
    "            if 'int3' not in val.lower() and 'nop' not in val.lower():\n",
    "                temp.append(int(key))\n",
    "    return temp\n",
    "\n",
    "\n",
    "\n",
    "def get_instructions(bin_file_path  ):\n",
    "    md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "    md.detail = True\n",
    "    offset_inst = {}\n",
    "\n",
    "    with open(bin_file_path, 'rb') as f:\n",
    "        try:\n",
    "            if BIN_FILE_TYPE == \"ELF\":\n",
    "                elffile = ELFFile(f)\n",
    "                textSection = elffile.get_section_by_name('.text').data()\n",
    "                text_section_offset = elffile.get_section_by_name('.text')['sh_offset']\n",
    "              \n",
    "            elif BIN_FILE_TYPE == \"PE\":\n",
    "        \n",
    "                        \n",
    "                pe_file = lief.parse(bin_file_path)\n",
    "                text_section = pe_file.get_section(\".text\")\n",
    "                text_section_offset = text_section.pointerto_raw_data\n",
    "                textSection = bytes(text_section.content)\n",
    "                \n",
    "        except Exception as e:\n",
    "                print(\"An error occurred:\", e ,bin_file_path)\n",
    "                return\n",
    "    \n",
    "        for byte_index in range(len(textSection)):\n",
    "            try:    \n",
    "    \n",
    "                instruction = next(md.disasm(textSection[byte_index: byte_index+15 ], text_section_offset + byte_index ), None)\n",
    "                offset_inst[text_section_offset+byte_index] = instruction\n",
    "                \n",
    "                # if instruction:\n",
    "                #     print(\"%d:\\t%s\\t%s _\\t%x\" %(int(instruction.address), instruction.mnemonic, instruction.op_str, instruction.size))\n",
    "                # else:\n",
    "                #     print(\"%d:\\t%s \" % (text_section_offset + byte_index  , 'invalid instruction') )\n",
    "    \n",
    "            except Exception as e:\n",
    "                print(traceback.print_exc() )\n",
    "                print(e)\n",
    "    return offset_inst\n",
    "\n",
    "ground_truth__jsons  =  os.listdir(ground_truth_json_dir) \n",
    "ghidra_predict_jsons    =  os.listdir(predict_json_dir)\n",
    "\n",
    "\n",
    "common_json_files = list(set(ground_truth__jsons) & set(ghidra_predict_jsons))\n",
    "print(len(common_json_files))\n",
    "common_json_files = common_json_files#[0:1]\n",
    "# common_json_files =['370cf902ac71f426c14725a24959e8de.json']\n",
    "all_TP= all_FP= all_FN= all_TN = 0\n",
    "\n",
    "for json_file_name in common_json_files:\n",
    "    # print('\\n\\n\\n',json_file_name)\n",
    "    ground_truth_json_path =  os.path.join(ground_truth_json_dir, json_file_name)\n",
    "    ghidra_predict_json_path =  os.path.join(predict_json_dir, json_file_name)\n",
    "    ground_truth_offsets = get_offsets(ground_truth_json_path)\n",
    "    predict_offsets = get_offsets(ghidra_predict_json_path)\n",
    "    \n",
    "    ground_truth_offsets_set = set(ground_truth_offsets)\n",
    "    predict_offsets_set = set(predict_offsets)\n",
    "\n",
    "    \n",
    "    superset = set(range( min(ground_truth_offsets) , max(ground_truth_offsets) ) )\n",
    "    \n",
    "    true_positive = len(ground_truth_offsets_set&predict_offsets_set)\n",
    "    false_positive = len(predict_offsets_set - ground_truth_offsets_set)\n",
    "    false_negative = len( ground_truth_offsets_set -predict_offsets_set )\n",
    "    true_negative = len( superset - ( ground_truth_offsets_set|predict_offsets_set)  )\n",
    "    \n",
    "    all_TP+=true_positive\n",
    "    all_FP+=false_positive\n",
    "    all_FN+=false_negative\n",
    "    all_TN+=true_negative\n",
    "    \n",
    "    print('\\ntrue_positive: ',true_positive , '\\n false_positive: ',false_positive ,'\\nfalse_negative:', false_negative , '\\ntrue_negative: ',true_negative)\n",
    "\n",
    "    continue\n",
    "    \n",
    "    bin_file_path = os.path.join(os.path.join(BIN_PATH ,  json_file_name.split('.')[0] ),  (json_file_name.split('.')[0]+ ('.exe' if BIN_FILE_TYPE == \"PE\" else '' )))\n",
    "    exhaustive_disasm = get_instructions(bin_file_path)\n",
    "    # print(exhaustive_disasm)\n",
    "    if exhaustive_disasm:\n",
    "      for offset in exhaustive_disasm:\n",
    "          if exhaustive_disasm[offset] is None:\n",
    "              continue\n",
    "          hash = '#' if offset in ground_truth_offsets else ' '\n",
    "          dollar = '$' if offset in predict_offsets else ' '\n",
    "\n",
    "          marker = ''\n",
    "          if offset in predict_offsets and offset not in ground_truth_offsets :\n",
    "              marker = '     >>>>>>>>      '*2\n",
    "          if hash=='#' or dollar=='$':\n",
    "              print( hash , dollar , hex(offset), exhaustive_disasm[offset].mnemonic+ exhaustive_disasm[offset].op_str , marker) \n",
    "          \n",
    "\n",
    "    else:\n",
    "        print('exhaustive diasm none')\n",
    "    # print(len(ground_truth_offsets) , len(predict_offsets))\n",
    "    # false_negatives = list(set(ground_truth_offsets) - set(predict_offsets))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4a451e-21a5-4815-8506-3e183348d7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 58942, FP: 629, FN: 0, TN: 568038\n"
     ]
    }
   ],
   "source": [
    "print(f\"TP: {all_TP}, FP: {all_FP}, FN: {all_FN}, TN: {all_TN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7586aaf9-0da5-4fdd-a383-2a3f094855e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9990\n",
      "Precision: 0.9894\n",
      "Recall: 1.0000\n",
      "F1-score: 0.9947\n"
     ]
    }
   ],
   "source": [
    "accuracy = (all_TP + all_TN) / (all_TP + all_TN + all_FP + all_FN)\n",
    "precision = all_TP / (all_TP + all_FP) if (all_TP + all_FP) > 0 else 0\n",
    "recall = all_TP / (all_TP + all_FN) if (all_TP + all_FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ea1f7-3173-437a-b4a8-0771b8b9ac68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
